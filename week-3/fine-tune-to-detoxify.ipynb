{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune FLAN-T5 with Reinforcement Learning (PPO) and (Parameter Efficient Fine Tuning) PEFT to Generate Less-Toxic Summaries\n",
    "\n",
    "In this notebook, we will fine-tune a FLAN-T5 model to generate less toxic content with Meta AI's hate speech reward model.\n",
    "\n",
    "The reward model is a binary classifier that predicts either \"not hate\" or \"hate\" for the given text. We will use Proximal Policy Optimization (PPO) to fine-tune and reduce the model's toxicity.\n",
    "\n",
    "## 1 - Set up Kernal\n",
    "```\n",
    "pip3 install --upgrade pip\n",
    "\n",
    "pip3 install --disable-pip-version-check \\\n",
    "    torch==2.0.0 \\\n",
    "    torchdata==0.6.0\n",
    "\n",
    "pip3 install \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.11.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    peft==0.3.0\n",
    "```\n",
    "\n",
    "## 2 - Load FLAN-T5 Model, Prepare Reward Model and Toxicity Evaluator\n",
    "\n",
    "### 2.1 - Load Data and FLAN-T5 Model Fine-Tuned with Summarization Instruction\n",
    "\n",
    "We will keep working with the same Hugging Face dataset DialogSum and the pre-trained model FLAN-T5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "model_name=\"google/flan-t5-base\"\n",
    "huggingface_dataset_name=\"knkarthick/dialogsum\"\n",
    "\n",
    "dataset_original = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to preprocess the dataset. We will take only a part of it, then filter the dialogues of a particular length (just to make those examples long enough and, at the same time, easy to read). Then wrap each dialogue with the instruction and tokenize the prompts. Save the token ids in the field `input_ids` and decoded version of the prompts in the field `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 8017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2005\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def build_dataset(model_name,\n",
    "                  dataset_name,\n",
    "                  input_min_text_length,\n",
    "                  input_max_text_length):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Tokenizer model name\n",
    "    - dataset_name (str): Name of the dataset to load.\n",
    "    - input_min_text_length (int): Minimum length of the dialogues.\n",
    "    - input_max_text_length (int): Maximum length of the dialogues.\n",
    "\n",
    "    Returns:\n",
    "    - dataset_splits (dataset.dataset_dict.DatasetDict): Preprocessed dataset contained train and test parts.\n",
    "    \"\"\"\n",
    "\n",
    "    # load dataset (only \"train\" part will be enough for this lab)\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "    # filter the dialogue of length between input_min_text_length and input_max_text_length\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
    "\n",
    "    # Prepare tokenizer. Setting device_map=\"auto\" allows to switch between GPU and CPU automatically.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "    def tokenize(sample):\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "\n",
    "        # This must be called \"query\", which is a requirement of our PPO library.\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "    \n",
    "    # Tokenize each dialogue\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "\n",
    "    # Split the dataset into train and test parts\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(model_name=model_name,\n",
    "                        dataset_name=huggingface_dataset_name,\n",
    "                        input_min_text_length=200,\n",
    "                        input_max_text_length=1000)\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lab, we fine-tuned the PEFT model with summarization instructions.\n",
    "We can load the local version from `../week-2/peft-dialogue-summary-checkpoint-local/adapter_model.bin`, since I don't have access to the full fine-tuned model from the s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# has already been copied\n",
    "# cp ../week-2/peft-dialogue-summary-checkpoint-local/adapter_model.bin ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a function to pull out the number of model parameters (it is the same as in the previous lab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_total_number_of_model_parameters(model):\n",
    "    print(f'{model.num_parameters():,}')\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    print(f'{model.num_parameters(only_trainable=True):,}')\n",
    "\n",
    "def print_percentage_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the adapter to the original FLAN-T5 model. In the previous lab we were adding the fully trained adapter only for inferences, so there was no need to pass LoRA configurations doing that. \n",
    "\n",
    "Now we need to pass them to the constructed PEFT model, also putting `is_trainable=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of model parameters:\n",
      "251,116,800\n",
      "PEFT model parameters to be updated:\n",
      "3,538,944\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, LoraConfig, TaskType\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r = 32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", 'v'],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, \n",
    "                                              torch_dtype=torch.bfloat16)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model,\n",
    "                                       './peft-dialogue-summary-checkpoint-local/',\n",
    "                                       lora_config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       device_map=\"auto\",\n",
    "                                       is_trainable=True)\n",
    "\n",
    "print(f\"Total number of model parameters:\")\n",
    "print_total_number_of_model_parameters(peft_model)\n",
    "\n",
    "print(f\"PEFT model parameters to be updated:\")\n",
    "print_number_of_trainable_model_parameters(peft_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we are preparing to fine-tune the LLM using Reinforcement Learning (RL). \n",
    "\n",
    "RL will be briefly discussed in the next section of this lab, but at this stage, we just need to prepare the Proximal Policy Optimization (PPO) model passing the instruct-fine-tuned PEFT model to it. PPO will be used to optimize the RL policy against the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/lvwerra/trl.git@25fa1bd\n",
      "  Cloning https://github.com/lvwerra/trl.git (to revision 25fa1bd) to /private/var/folders/9r/667t4_w13xqbc_xnc9srccvm0000gn/T/pip-req-build-mvxup62y\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git /private/var/folders/9r/667t4_w13xqbc_xnc9srccvm0000gn/T/pip-req-build-mvxup62y\n",
      "\u001b[33m  WARNING: Did not find branch or tag '25fa1bd', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q 25fa1bd\n",
      "  Resolved https://github.com/lvwerra/trl.git to commit 25fa1bd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/homebrew/lib/python3.11/site-packages (from trl==0.4.2.dev0) (2.0.0)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /opt/homebrew/lib/python3.11/site-packages (from trl==0.4.2.dev0) (4.27.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/homebrew/lib/python3.11/site-packages (from trl==0.4.2.dev0) (1.26.1)\n",
      "Requirement already satisfied: accelerate in /opt/homebrew/lib/python3.11/site-packages (from trl==0.4.2.dev0) (0.24.1)\n",
      "Requirement already satisfied: datasets in /opt/homebrew/lib/python3.11/site-packages (from trl==0.4.2.dev0) (2.14.6)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.19.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tahaafzal/Library/Python/3.11/lib/python/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (4.66.1)\n",
      "Requirement already satisfied: psutil in /Users/tahaafzal/Library/Python/3.11/lib/python/site-packages (from accelerate->trl==0.4.2.dev0) (5.9.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (14.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->trl==0.4.2.dev0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from datasets->trl==0.4.2.dev0) (3.8.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl==0.4.2.dev0) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tahaafzal/Library/Python/3.11/lib/python/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl==0.4.2.dev0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tahaafzal/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.4.2.dev0) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "PPO model parameters to be updated (ValueHead + 769 params):\n",
      "\n",
      "trainable model parameters: 3539713\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/lvwerra/trl.git@25fa1bd\n",
    "\n",
    "from trl import AutoModelForSeq2SeqLMWithValueHead\n",
    "\n",
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,\n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_percentage_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During PPO, only a few parameters will be updated. Specifically, the parameters of the `ValueHead`. \n",
    "\n",
    "More information about this class of models can be found in the [documentation](https://huggingface.co/docs/trl/main/en/models#trl.create_reference_model). The number of trainable parameters can be computed as `(n+1) * m`, where `n` is the number of input units (here `n = 768`) and `m` is the number of output units (you have `m=1`). The `+1` term in the equation takes into account the bias term.\n",
    "\n",
    "Now create a frozen copy of the PPO which will not be fine-tuned - a reference model. The reference model will represent the LLM before detoxification. None of the parameters of the reference model will be updated during PPO training. This is on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 0\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from trl import create_reference_model\n",
    "\n",
    "ref_model = create_reference_model(ppo_model)\n",
    "print(f'Reference model parameters to be updated:\\n{print_percentage_of_trainable_model_parameters(ref_model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Prepare Reward Model\n",
    "\n",
    "**Reinforcement Learning (RL)** is one type of machine learning where agents take actions in an environment aimed at maximizing their cumulative rewards. The agent's behavior is defined by the **policy**. And the goal of the reinforcement learning is for the agent to learn an optimal, or nearly-optimal, policy that maximizes the **reward function**.\n",
    "\n",
    "In the previous section, the original original policy is based on the instruct PEFT model - this is the LLM before detoxification. Then We could ask human labor, to give feedback on the outputs' toxicity. However, it can be expensive to use them for the entire fine-tuning process. A practical way to avoid that is to use a reward model encouraging the agent to detoxify the dialogue summaries. Then intuitive approach would be to do some form of sentiment analysis across two classes (`nothate` and `hate`) And give a higher award if there is a chance of getting in class `nothate` as an output.\n",
    "\n",
    "We will use [Meta AI's RoBERTa-based hate speech model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target) for the reward model. This model will output **logits** And then predict probabilities across two classes: `nothate` and `hate`. The logits of the output `nothate` Will be taking as a positive reward. Then the model Will be fine tuned with PPO using those reward values.\n",
    "\n",
    " Create the instance of the required model for the RoBERTa model. We also need to load a tokenizer to test the model. Noticed that the model label `0`  will correspond to the class `nothate` and label `1` to the class `hate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "\n",
    "print(toxicity_model.config.id2label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some non-toxic text, tokenize it, and pass it to the model. \n",
    "Print the output logits, probabilities, and the corresponding reward that will be used for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
    "# throws a runtime error\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# get the logits for \"not hate\" - this is the reward!\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (high): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show a toxic comment. This will have a low reward because it is more toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
    "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids\n",
    "# throws a runtime error\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# Get the logits for \"not hate\" - this is the reward!\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist() \n",
    "print(f'reward (low): {nothate_reward}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Hugging Face inference pipeline to simplify the code for the toxicity reward model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model output:\n",
      "For non-toxic text\n",
      "[{'label': 'nothate', 'score': 3.114098072052002}, {'label': 'hate', 'score': -2.4896154403686523}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706337705254555}]\n",
      "For toxic text\n",
      "[{'label': 'hate', 'score': 0.37227004766464233}, {'label': 'nothate', 'score': -0.6921156048774719}]\n",
      "[{'label': 'hate', 'score': 0.7435277700424194}, {'label': 'nothate', 'score': 0.25647225975990295}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", \n",
    "                          model=toxicity_model_name, \n",
    "                          device=device)\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"Reward model output:\")\n",
    "print(\"For non-toxic text\")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "print(\"For toxic text\")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are the logits for both `nothate` (positive) and `hate` (negative) classes. But PPO will be using logits only of the `nothate` class as the positive reward signal is used to help detoxify the LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 3.114098072052002}, {'label': 'hate', 'score': -2.4896154403686523}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706337705254555}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'hate', 'score': 0.37227004766464233}, {'label': 'nothate', 'score': -0.6921156048774719}]\n",
      "[{'label': 'hate', 'score': 0.7435277700424194}, {'label': 'nothate', 'score': 0.25647225975990295}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Evaluate Toxicity\n",
    "\n",
    "To evaluate the model before and after fine-tuning/detoxification you need to set up the [toxicity evaluation metric](https://huggingface.co/spaces/evaluate-measurement/toxicity). The toxicity score is a decimal value between 0 and 1 where 1 is the highest toxicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.08k/6.08k [00:00<00:00, 24.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "toxicity_evaluator = evaluate.load(\"toxicity\", \n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to calculate toxicity for the same sentences as in section 2.2. It's no surprise that the toxicity scores are the probabilities of `hate` class returned directly from the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score for non-toxic text:\n",
      "[0.0036706337705254555]\n",
      "\n",
      "Toxicity score for toxic text:\n",
      "[0.7435277700424194]\n"
     ]
    }
   ],
   "source": [
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    non_toxic_text\n",
    "])\n",
    "\n",
    "print(\"Toxicity score for non-toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])\n",
    "\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    toxic_text\n",
    "])\n",
    "\n",
    "print(\"\\nToxicity score for toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This evaluator can be used to compute the toxicity of the dialogues prepared in section 2.1. We will need to pass the test dataset (`dataset[\"test\"]`), the same tokenizer which was used in that section, the frozen PEFT model prepared in section 2.2, and the toxicity evaluator. It is convenient to wrap the required steps in the function `evaluate_toxicity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "def evaluate_toxicity(model,\n",
    "                      toxicity_evaluator,\n",
    "                      tokenizer,\n",
    "                      dataset,\n",
    "                      num_samples):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model (trl model): Model to be evaluated.\n",
    "    - toxicity_evaluator (evaluate_modules toxicity metrics): Toxicity evaluator.\n",
    "    - tokenizer (transformers tokenizer): Tokenizer to be used.\n",
    "    - dataset (dataset): Input dataset for the evaluation.\n",
    "    - num_samples (int): Maximum number of samples for the evaluation.\n",
    "        \n",
    "    Returns:\n",
    "    tuple: A tuple containing two numpy.float64 values:\n",
    "    - mean (numpy.float64): Mean of the samples toxicity.\n",
    "    - std (numpy.float64): Standard deviation of the samples toxicity.\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens=100\n",
    "\n",
    "    toxicities = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "\n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "        \n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "        \n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "    \n",
    "    # Compute mean & std using np.\n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "        \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now perform the calculation of the model toxicity before fine-tuning/detoxification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:58,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] before detox: [0.020027383241209794, 0.026915058424599524]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model, \n",
    "                                                                          toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                          tokenizer=tokenizer, \n",
    "                                                                          dataset=dataset[\"test\"], \n",
    "                                                                          num_samples=10)\n",
    "\n",
    "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Perform Fine-Tuning to Detoxify the Summaries\n",
    "\n",
    "Optimize a RL policy against the reward model using Proximal Policy Optimization (PPO).\n",
    "\n",
    "### 3.1 Initialize `PPOTrainer`\n",
    "For the `PPOTrainer` initialization, you will need a collator. Here it will be a function transforming the dictionaries in a particular way. You can define and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
      "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
     ]
    }
   ],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the configuration parameters. Load the `ppo_model` and the tokenizer. You will also load a frozen version of the model `ref_model`. The first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This works as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import PPOConfig, PPOTrainer\n",
    "\n",
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config,\n",
    "                         model=ppo_model,\n",
    "                         ref_model=ref_model,\n",
    "                         tokenizer=tokenizer,\n",
    "                         dataset=dataset[\"train\"],\n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fine-Tune the Model\n",
    "\n",
    "The fine-tuning loop consists of the following main steps:\n",
    "\n",
    "1. Get the query responses from the policy LLM (PEFT model).\n",
    "2. Get sentiments for query/responses from hate speech RoBERTa model.\n",
    "3. Optimize policy with PPO using the (query, response, reward) triplet.\n",
    "\n",
    "The operation is running if you see the following metrics appearing:\n",
    "\n",
    " - `objective/kl`: minimize kl divergence,\n",
    " - `ppo/returns/mean`: maximize mean returns,\n",
    " - `ppo/policy/advantages_mean`: maximize advantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.7000e+01, 6.0800e+02, 8.0000e+00, 3.9090e+03, 6.0000e+00,\n",
       "         6.8000e+01, 2.7000e+01, 3.1000e+01, 5.1000e+01, 3.4100e+02, 5.9000e+01,\n",
       "         4.1700e+02, 1.4900e+02, 1.2000e+01, 1.6900e+02, 8.2000e+01, 2.3580e+03,\n",
       "         9.5100e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 1.3630e+04, 6.0000e+00, 3.4000e+01, 3.1000e+01,\n",
       "         7.0000e+00, 1.1340e+03, 5.1400e+02, 5.0000e+00, 1.4850e+03, 1.3000e+01,\n",
       "         6.6000e+01, 6.0000e+00, 2.7800e+02, 3.1000e+01, 1.7000e+01, 2.6120e+03,\n",
       "         1.2000e+01, 9.1900e+02, 3.4000e+01, 3.0000e+01, 5.0000e+00, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 1.3031e+04,\n",
       "         3.4000e+01, 5.5000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 3.7000e+01, 2.9000e+01, 1.0362e+04, 8.0000e+00,\n",
       "         3.8100e+02, 5.0000e+00, 2.7500e+02, 1.4230e+03, 1.2000e+01, 2.7850e+03,\n",
       "         8.0000e+00, 3.0000e+00, 3.1000e+01, 7.0000e+00, 9.8900e+02, 3.1000e+01,\n",
       "         2.2180e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02,\n",
       "         4.6630e+03, 1.0000e+01, 4.6600e+02, 3.1000e+01, 7.0000e+00, 6.6000e+01,\n",
       "         5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.8268e+04, 2.3100e+02, 5.0000e+00, 1.1420e+03, 1.4300e+02,\n",
       "         4.1700e+02, 1.2000e+01, 1.6489e+04, 8.0000e+00, 9.1210e+03, 3.3400e+02,\n",
       "         3.6000e+02, 1.2740e+03, 5.0000e+00, 2.7500e+02, 6.5300e+02, 5.9000e+01,\n",
       "         1.2000e+01, 2.3280e+03, 3.4000e+01, 5.0000e+00, 9.4000e+01, 3.1000e+01,\n",
       "         7.0000e+00, 1.8659e+04, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         5.3600e+02, 4.6630e+03, 1.0000e+01, 1.8040e+03, 1.8670e+03, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         2.7500e+02, 8.0000e+01, 7.2000e+01, 5.8900e+02, 1.0000e+01, 4.9300e+02,\n",
       "         4.1700e+02, 1.2000e+01, 7.2600e+02, 8.0000e+00, 9.5100e+02, 2.8760e+03,\n",
       "         3.3400e+02, 8.4700e+02, 5.5000e+01, 2.0698e+04, 1.0000e+01, 3.0000e+00,\n",
       "         1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.5210e+03, 2.5000e+01, 1.2600e+02, 1.2000e+01, 4.8000e+01,\n",
       "         4.9600e+02, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 2.1630e+03, 6.0000e+00, 2.7000e+01, 3.1000e+01,\n",
       "         5.1000e+01, 1.2600e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         5.3600e+02, 4.6630e+03, 1.0000e+01, 2.7000e+01, 7.0000e+00, 4.8000e+01,\n",
       "         3.9000e+01, 1.6600e+02, 2.1500e+02, 1.6000e+01, 1.9000e+03, 5.8000e+01,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         2.7000e+01, 1.0250e+04, 4.5000e+01, 4.3000e+02, 4.9600e+02, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01,\n",
       "         2.8400e+03, 4.1000e+02, 2.5000e+01, 2.0250e+03, 4.5000e+01, 5.8000e+01,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         2.7000e+01, 4.7000e+01, 4.4000e+01, 2.1040e+03, 2.5400e+02, 2.7400e+02,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.6150e+03, 4.1000e+02, 2.5000e+01, 2.0250e+03, 5.8000e+01,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         2.7000e+01, 4.7000e+01, 3.5200e+02, 1.2000e+01, 2.8100e+02, 2.7000e+02,\n",
       "         1.6600e+02, 6.0000e+00, 6.8000e+01, 8.2000e+01, 1.3082e+04, 9.3550e+03,\n",
       "         3.1000e+01, 1.7000e+01, 2.0700e+02, 6.3100e+02, 5.0000e+00, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 3.9630e+03,\n",
       "         2.5000e+01, 1.1400e+02, 3.4000e+01, 4.4000e+01, 2.1040e+03, 2.5400e+02,\n",
       "         5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.1040e+03, 2.5400e+02, 1.9000e+01, 4.6000e+01, 3.9040e+03,\n",
       "         4.9600e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02,\n",
       "         4.6630e+03, 1.0000e+01, 1.5480e+03, 6.0000e+00, 2.7000e+01, 1.6630e+03,\n",
       "         2.5000e+01, 5.8510e+03, 2.7000e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 2.7000e+01, 3.1000e+01,\n",
       "         5.1000e+01, 4.1700e+02, 2.7000e+01, 3.1000e+01, 1.9500e+02, 1.1400e+02,\n",
       "         3.4000e+01, 2.7000e+02, 5.0000e+00, 2.0698e+04, 1.0000e+01, 3.0000e+00,\n",
       "         1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.1850e+03, 1.9000e+01, 8.0000e+00, 2.0000e+02, 4.7750e+03,\n",
       "         2.1000e+01, 1.3404e+04, 1.3000e+01, 8.0000e+00, 1.2360e+03, 7.0210e+03,\n",
       "         6.0000e+00, 1.9000e+01, 2.9000e+01, 3.1000e+01, 1.7000e+01, 3.0000e+00,\n",
       "         8.8000e+01, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 1.5480e+03, 6.0000e+00, 2.4000e+01, 4.0240e+03,\n",
       "         7.5100e+02, 3.1000e+01, 1.7000e+01, 3.6000e+01, 3.0000e+00, 1.7900e+02,\n",
       "         1.2000e+01, 1.3690e+03, 8.0000e+00, 4.3560e+03, 3.0000e+00, 3.2270e+03,\n",
       "         3.0000e+00, 8.8000e+01, 2.3470e+03, 1.2800e+02, 2.9420e+03, 2.9020e+03,\n",
       "         4.5000e+01, 8.8700e+02, 4.8100e+02, 5.0000e+00, 2.7500e+02, 2.7000e+01,\n",
       "         3.1000e+01, 5.1000e+01, 5.9000e+01, 4.1700e+02, 8.1000e+01, 2.4000e+01,\n",
       "         5.0000e+00, 2.0698e+04, 1.0000e+01, 3.0000e+00, 1.0000e+00],\n",
       "        device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.8040e+03, 1.3790e+03, 6.0000e+00, 1.1170e+03, 5.1650e+03,\n",
       "         2.4601e+04, 5.0000e+00, 9.3200e+02, 2.7000e+01, 1.9900e+02, 2.5000e+01,\n",
       "         5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.1630e+03, 6.0000e+00, 1.0300e+02, 2.5000e+01, 4.3000e+01,\n",
       "         1.3600e+02, 3.7420e+03, 7.5340e+03, 1.2000e+01, 1.5985e+04, 3.0000e+01,\n",
       "         1.7180e+03, 1.7353e+04, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         5.3600e+02, 4.6630e+03, 1.0000e+01, 5.5500e+02, 7.9800e+02, 7.5400e+02,\n",
       "         5.0000e+00, 2.1630e+03, 6.0000e+00, 1.3200e+02, 1.9000e+01, 3.0000e+00,\n",
       "         9.0000e+00, 3.7770e+03, 4.4000e+01, 5.8600e+02, 1.0000e+01, 2.1280e+03,\n",
       "         3.2460e+03, 1.1000e+01, 8.0000e+01, 4.4000e+01, 3.1400e+02, 1.0000e+01,\n",
       "         2.4450e+03, 3.2460e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 2.6200e+02, 9.7320e+03, 1.3000e+01,\n",
       "         2.7300e+02, 1.3300e+02, 3.6000e+01, 1.3990e+03, 5.0000e+00, 1.0720e+03,\n",
       "         2.5000e+01, 8.1700e+02, 1.4000e+02, 1.4900e+02, 2.3100e+02, 3.0000e+00,\n",
       "         9.0000e+00, 1.2050e+03, 3.7770e+03, 1.3300e+02, 5.8300e+02, 5.8000e+01,\n",
       "         2.7000e+01, 3.1000e+01, 1.9500e+02, 3.6000e+01, 7.6460e+03, 3.0000e+01,\n",
       "         1.7180e+03, 6.7860e+03, 1.8000e+01, 1.4672e+04, 5.0000e+00, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 2.2077e+04,\n",
       "         6.0000e+00, 2.6800e+02, 6.0000e+00, 4.2000e+01, 1.6600e+02, 8.5300e+02,\n",
       "         5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.2077e+04, 6.0000e+00, 7.5400e+02, 5.0000e+00, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 6.9020e+03,\n",
       "         6.0000e+00, 2.4000e+01, 5.6000e+01, 3.6000e+01, 1.7005e+04, 5.0000e+00,\n",
       "         4.0730e+03, 3.7420e+03, 3.7770e+03, 1.3300e+02, 2.5000e+01, 1.1400e+02,\n",
       "         1.2000e+01, 2.4000e+02, 3.0000e+01, 1.7180e+03, 1.7353e+04, 5.8000e+01,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         3.7000e+01, 8.5370e+03, 5.4110e+03, 2.0698e+04, 1.0000e+01, 3.0000e+00,\n",
       "         1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 5.7100e+02, 1.8600e+02, 2.3270e+03, 1.0989e+04, 4.0500e+02,\n",
       "         3.9000e+01, 3.4900e+02, 3.8040e+03, 5.8000e+01, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 1.0100e+02, 4.3000e+01,\n",
       "         1.9200e+02, 2.3270e+03, 1.0989e+04, 5.0000e+00, 2.9900e+02, 3.2100e+02,\n",
       "         1.3000e+01, 1.3500e+02, 4.3000e+01, 1.2040e+03, 3.8500e+02, 1.0730e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.3770e+03, 2.3270e+03, 1.0989e+04, 3.3000e+01, 3.0000e+00,\n",
       "         1.7300e+02, 9.8420e+03, 3.4200e+02, 5.0000e+00, 2.9900e+02, 1.2800e+02,\n",
       "         1.3000e+01, 1.3500e+02, 1.0300e+02, 3.0000e+00, 9.0000e+00, 1.8200e+02,\n",
       "         1.2450e+03, 6.1300e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 2.9900e+02, 2.7000e+01, 7.0000e+02,\n",
       "         2.2461e+04, 4.3000e+02, 9.3600e+03, 5.0000e+00, 4.5100e+02, 1.9000e+01,\n",
       "         7.2000e+01, 3.9190e+03, 1.1000e+01, 1.3300e+03, 1.2000e+01, 4.3000e+01,\n",
       "         9.1200e+02, 1.3000e+01, 1.6000e+02, 2.9300e+02, 5.0000e+00, 2.9900e+02,\n",
       "         8.0000e+00, 3.1690e+03, 1.9000e+01, 2.5500e+02, 1.9000e+01, 3.0000e+00,\n",
       "         9.0000e+00, 2.2300e+02, 7.0000e+00, 1.5440e+03, 2.5350e+03, 2.8000e+01,\n",
       "         1.2800e+02, 1.3000e+01, 1.7800e+02, 5.0000e+00, 4.5100e+02, 1.3300e+02,\n",
       "         8.1700e+02, 2.5000e+01, 1.2500e+02, 1.2000e+01, 1.0300e+02, 1.1000e+01,\n",
       "         2.1300e+02, 1.2000e+01, 4.7400e+02, 3.7800e+02, 5.0000e+00, 2.0698e+04,\n",
       "         1.0000e+01, 3.0000e+00, 1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.8040e+03, 1.3790e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 1.6182e+04, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01,\n",
       "         4.5890e+03, 1.6000e+01, 5.0000e+00, 9.2500e+02, 1.7000e+01, 3.2300e+02,\n",
       "         5.0000e+00, 8.5200e+02, 6.0000e+00, 2.5000e+01, 3.1000e+01, 6.0000e+01,\n",
       "         3.0000e+00, 9.0000e+00, 1.2600e+02, 1.8680e+03, 6.0000e+00, 3.3000e+01,\n",
       "         2.9000e+01, 3.1000e+01, 1.7000e+01, 2.5000e+01, 5.8000e+01, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 2.1630e+03,\n",
       "         6.0000e+00, 2.4000e+01, 3.1000e+01, 7.0000e+00, 2.6900e+02, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01,\n",
       "         6.9020e+03, 5.0000e+00, 2.6400e+02, 2.7000e+01, 3.1000e+01, 2.6000e+01,\n",
       "         1.1400e+02, 3.9400e+02, 1.2000e+01, 9.8700e+02, 2.5000e+01, 1.2800e+02,\n",
       "         7.4600e+02, 1.6600e+02, 5.0000e+00, 8.5200e+02, 6.0000e+00, 4.3000e+01,\n",
       "         2.5000e+01, 6.6400e+02, 1.4100e+02, 1.3600e+02, 2.2610e+03, 2.1154e+04,\n",
       "         4.2000e+01, 1.0649e+04, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 7.1000e+01, 4.3350e+03, 4.5530e+03,\n",
       "         2.7000e+01, 5.3000e+02, 4.5000e+01, 1.5560e+03, 3.3700e+03, 1.1600e+02,\n",
       "         2.7000e+01, 4.7000e+01, 1.1030e+04, 2.7000e+01, 4.7000e+01, 1.6000e+01,\n",
       "         8.0000e+00, 4.9600e+02, 3.7200e+02, 4.4000e+01, 2.4000e+01, 9.7000e+01,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.1345e+04, 1.3070e+03, 5.8000e+01, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 4.6500e+02, 5.0000e+00,\n",
       "         1.3323e+04, 4.5000e+01, 2.4000e+01, 6.0000e+00, 1.3270e+03, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01,\n",
       "         2.7500e+02, 4.3000e+01, 2.5000e+01, 1.4100e+02, 1.3600e+02, 2.6730e+03,\n",
       "         1.3000e+01, 1.3600e+02, 7.7300e+02, 5.8000e+01, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 8.5200e+02, 8.0000e+00,\n",
       "         1.6300e+02, 9.7000e+01, 2.7000e+01, 3.1000e+01, 1.6200e+02, 1.1800e+02,\n",
       "         1.2000e+01, 2.8330e+03, 2.7400e+02, 4.7000e+01, 1.1600e+02, 2.7000e+01,\n",
       "         8.2380e+03, 8.2000e+01, 4.5530e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 1.1456e+04, 5.0000e+00,\n",
       "         2.3720e+03, 1.8500e+04, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 2.1630e+03, 6.0000e+00, 1.2000e+01,\n",
       "         5.7840e+03, 1.1000e+01, 1.0003e+04, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 5.7100e+02, 1.0300e+02,\n",
       "         2.5000e+01, 8.9220e+03, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 3.2800e+02, 3.2100e+02, 1.4300e+02,\n",
       "         1.4000e+02, 3.0000e+00, 7.0000e+00, 2.9000e+01, 1.5000e+01, 2.1870e+03,\n",
       "         3.0000e+00, 9.0000e+00, 7.2000e+02, 5.0000e+00, 9.4280e+03, 1.3070e+03,\n",
       "         5.0000e+00, 2.0698e+04, 1.0000e+01, 3.0000e+00, 1.0000e+00],\n",
       "        device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 3.9260e+03, 1.9500e+02, 2.7000e+01, 1.4320e+03, 2.5000e+01,\n",
       "         9.5000e+01, 2.5800e+02, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 2.7000e+01, 2.7800e+02, 3.1000e+01,\n",
       "         1.7000e+01, 2.1400e+02, 5.0000e+00, 3.7000e+01, 2.1170e+03, 5.6000e+01,\n",
       "         3.6000e+01, 3.1000e+02, 1.2820e+03, 4.4000e+01, 2.4000e+01, 9.7000e+01,\n",
       "         5.0000e+00, 1.4800e+02, 2.1400e+02, 1.2500e+02, 3.4000e+01, 3.1000e+01,\n",
       "         7.0000e+00, 1.1400e+02, 2.2700e+02, 3.0000e+00, 9.0000e+00, 4.2190e+03,\n",
       "         5.0000e+00, 2.7000e+01, 4.7000e+01, 1.6310e+03, 1.3000e+01, 3.0000e+00,\n",
       "         1.1907e+04, 8.0000e+00, 2.4120e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 4.5400e+02, 6.3500e+02,\n",
       "         2.3300e+02, 1.9600e+02, 1.7000e+01, 5.6000e+01, 3.6000e+01, 1.4800e+03,\n",
       "         5.0000e+00, 5.4900e+02, 1.0600e+02, 3.1000e+01, 1.7000e+01, 2.4000e+01,\n",
       "         3.6000e+01, 3.0000e+00, 9.0000e+00, 7.2000e+02, 5.1070e+03, 5.8000e+01,\n",
       "         2.7000e+01, 3.1000e+01, 5.1000e+01, 5.9000e+01, 3.1640e+03, 2.5000e+01,\n",
       "         2.1400e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 4.6600e+02, 3.1000e+01, 7.0000e+00, 3.1000e+02,\n",
       "         7.7300e+02, 1.3000e+01, 2.5000e+01, 5.0000e+00, 2.7000e+01, 3.1000e+01,\n",
       "         1.6200e+02, 9.2000e+01, 8.1600e+02, 1.3000e+01, 6.5200e+02, 3.0000e+00,\n",
       "         9.0000e+00, 9.2560e+03, 6.0000e+00, 6.8000e+01, 2.5800e+02, 1.3200e+02,\n",
       "         3.1000e+01, 7.0000e+00, 3.4100e+02, 8.0000e+00, 2.1170e+03, 1.2000e+01,\n",
       "         3.5160e+03, 8.1000e+01, 5.0000e+00, 2.7000e+01, 3.1700e+02, 8.2000e+01,\n",
       "         9.2600e+02, 8.0000e+02, 1.9000e+01, 8.0000e+00, 2.0000e+02, 5.0000e+00,\n",
       "         2.0698e+04, 1.0000e+01, 3.0000e+00, 1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.7000e+01, 7.0000e+00, 2.9000e+01, 3.1000e+01, 1.7000e+01,\n",
       "         4.8000e+01, 2.4800e+02, 5.8000e+01, 2.7000e+01, 3.7300e+02, 1.1140e+03,\n",
       "         1.2000e+01, 2.9300e+02, 3.0000e+00, 9.0000e+00, 3.7970e+03, 6.0000e+00,\n",
       "         6.1900e+02, 9.1000e+01, 1.6000e+01, 8.0000e+00, 6.8400e+02, 6.0000e+00,\n",
       "         1.6040e+03, 8.2000e+01, 2.9300e+02, 5.4200e+02, 5.5000e+01, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 1.0000e+02,\n",
       "         1.9000e+01, 1.8200e+02, 7.8600e+02, 5.0000e+00, 4.2290e+03, 2.7000e+01,\n",
       "         4.3000e+01, 1.2000e+01, 2.5613e+04, 6.0000e+00, 2.7000e+01, 2.7800e+02,\n",
       "         3.1000e+01, 1.7000e+01, 2.1400e+02, 8.0000e+00, 1.6600e+02, 5.8900e+02,\n",
       "         8.1000e+01, 1.3293e+04, 5.5000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         5.3600e+02, 4.6630e+03, 1.0000e+01, 4.6600e+02, 3.1000e+01, 7.0000e+00,\n",
       "         1.3990e+03, 5.5000e+01, 1.0080e+03, 3.1000e+01, 1.7000e+01, 3.5160e+03,\n",
       "         8.1000e+01, 3.4000e+01, 5.5000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 3.6300e+02, 4.7000e+01, 2.4000e+01,\n",
       "         5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.2877e+04, 6.0000e+00, 3.4000e+01, 4.7000e+01, 1.3100e+02,\n",
       "         3.0000e+00, 9.0000e+00, 1.8174e+04, 5.5000e+01, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 2.7500e+02, 2.4000e+01,\n",
       "         5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 9.4000e+01, 3.1000e+01, 7.0000e+00, 1.3100e+02, 8.0000e+00,\n",
       "         9.3210e+03, 7.0000e+00, 2.4000e+01, 3.3000e+01, 3.0000e+00, 3.4840e+03,\n",
       "         8.1280e+03, 1.4700e+02, 1.3200e+02, 5.0000e+00, 1.0100e+02, 5.4000e+01,\n",
       "         3.7020e+03, 1.3500e+02, 8.6500e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 3.6300e+02, 4.7000e+01,\n",
       "         2.4000e+01, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02,\n",
       "         4.6630e+03, 1.0000e+01, 1.6354e+04, 6.0000e+00, 5.8300e+03, 6.0000e+00,\n",
       "         9.4000e+01, 3.1000e+01, 7.0000e+00, 1.3100e+02, 3.0000e+00, 9.0000e+00,\n",
       "         1.5184e+04, 5.0000e+00, 2.2877e+04, 5.5000e+01, 2.2877e+04, 6.0000e+00,\n",
       "         2.4000e+01, 4.7000e+01, 1.3100e+02, 8.0000e+00, 1.0235e+04, 1.1000e+01,\n",
       "         2.7800e+02, 4.3970e+03, 7.0000e+00, 2.4000e+01, 3.3000e+01, 1.6000e+01,\n",
       "         8.0000e+00, 5.7110e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 1.4800e+02, 2.1400e+02, 1.2500e+02,\n",
       "         5.8000e+01, 2.7000e+01, 2.7800e+02, 3.1000e+01, 1.7000e+01, 3.1700e+02,\n",
       "         2.7000e+01, 5.4000e+01, 8.0930e+03, 3.4000e+01, 2.7000e+02, 9.1000e+01,\n",
       "         1.6000e+01, 8.0000e+00, 1.8137e+04, 5.0000e+00, 2.7000e+01, 3.1000e+01,\n",
       "         5.1000e+01, 3.5200e+02, 2.2300e+02, 1.2000e+01, 8.0000e+00, 6.9000e+02,\n",
       "         5.5000e+01, 2.0698e+04, 1.0000e+01, 3.0000e+00, 1.0000e+00],\n",
       "        device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 5.3960e+03, 4.6900e+02, 6.0000e+00, 1.9000e+01, 2.9000e+01,\n",
       "         3.1000e+01, 1.7000e+01, 3.4000e+01, 5.8000e+01, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 2.1630e+03, 6.0000e+00,\n",
       "         3.4000e+01, 1.9000e+01, 5.0000e+00, 2.7000e+01, 1.6630e+03, 2.4000e+01,\n",
       "         3.4000e+01, 1.3300e+02, 3.4120e+03, 1.1000e+01, 1.6330e+03, 3.2600e+02,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.2120e+03, 6.0000e+00, 3.9600e+02, 5.0000e+00, 1.0000e+02,\n",
       "         1.9000e+01, 7.2250e+03, 2.1000e+01, 9.3200e+02, 5.0000e+00, 2.7000e+01,\n",
       "         2.7800e+02, 3.1000e+01, 1.7000e+01, 1.4230e+03, 3.4000e+01, 6.6400e+02,\n",
       "         2.7100e+02, 7.8000e+01, 1.3120e+03, 1.1000e+01, 2.1920e+03, 1.6000e+01,\n",
       "         9.3200e+02, 2.7400e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 1.4800e+02, 3.3000e+01, 4.5000e+01,\n",
       "         2.5990e+03, 2.5800e+02, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         5.3600e+02, 4.6630e+03, 1.0000e+01, 9.3300e+02, 3.1000e+02, 5.0000e+00,\n",
       "         2.7000e+01, 4.7000e+01, 2.1700e+03, 1.6000e+01, 3.7150e+03, 6.0000e+00,\n",
       "         6.8000e+01, 2.7000e+01, 3.1000e+01, 1.6200e+02, 4.1140e+03, 2.7000e+02,\n",
       "         2.1000e+01, 3.0000e+00, 3.2400e+02, 2.0300e+02, 2.3000e+02, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         4.9900e+02, 2.0390e+03, 1.1000e+01, 2.7000e+01, 4.3000e+01, 1.3100e+02,\n",
       "         2.3010e+03, 2.7000e+02, 4.5000e+01, 1.1494e+04, 5.0000e+00, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 1.8268e+04,\n",
       "         2.1070e+03, 1.6000e+01, 1.1494e+04, 6.0000e+00, 1.9000e+01, 2.9000e+01,\n",
       "         3.1000e+01, 1.7000e+01, 3.4000e+01, 5.8000e+01, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 2.1630e+03, 5.0000e+00,\n",
       "         4.6600e+02, 3.1000e+01, 7.0000e+00, 5.7200e+02, 6.2000e+01, 2.3010e+03,\n",
       "         5.0000e+00, 2.9900e+02, 6.2000e+01, 7.3700e+02, 3.1000e+01, 1.7000e+01,\n",
       "         2.1400e+02, 2.4000e+01, 3.4000e+01, 1.3300e+02, 3.6000e+01, 7.8000e+01,\n",
       "         1.3120e+03, 2.7000e+02, 5.0000e+00, 1.0100e+02, 2.2500e+02, 4.3000e+01,\n",
       "         2.7670e+03, 1.2000e+01, 1.8260e+03, 5.0000e+00, 5.3100e+02, 2.5000e+01,\n",
       "         3.1700e+02, 2.4000e+01, 6.2000e+01, 3.1000e+01, 1.6200e+02, 4.7850e+03,\n",
       "         8.0000e+00, 2.6010e+03, 6.0000e+00, 5.7000e+01, 8.0000e+00, 1.9400e+02,\n",
       "         5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 4.6500e+02, 5.0000e+00, 9.4000e+01, 3.1000e+01, 7.0000e+00,\n",
       "         3.0000e+00, 9.0000e+00, 4.2070e+03, 6.3000e+01, 7.0000e+00, 3.0000e+00,\n",
       "         9.0000e+00, 3.8500e+02, 1.4800e+03, 5.0000e+00, 2.0698e+04, 1.0000e+01,\n",
       "         3.0000e+00, 1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.5210e+03, 1.3200e+02, 1.1800e+03, 1.6370e+03, 1.6000e+01,\n",
       "         4.8000e+01, 5.3530e+03, 5.8000e+01, 2.7000e+01, 3.1000e+01, 1.6200e+02,\n",
       "         1.1800e+02, 7.5700e+03, 1.2000e+01, 6.6100e+02, 1.6000e+01, 8.0000e+00,\n",
       "         1.3790e+03, 7.0000e+00, 6.0000e+00, 6.8000e+01, 2.7000e+01, 2.7800e+02,\n",
       "         3.1000e+01, 1.7000e+01, 1.1400e+02, 1.2000e+01, 1.0300e+02, 3.4000e+01,\n",
       "         2.2380e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 1.1475e+04, 6.0000e+00, 1.3200e+02, 1.9000e+01,\n",
       "         3.0000e+00, 9.0000e+00, 5.6300e+02, 2.4000e+01, 7.8640e+03, 4.4000e+01,\n",
       "         8.0000e+00, 2.4470e+03, 3.0000e+00, 9.0000e+00, 3.6000e+02, 6.4380e+03,\n",
       "         4.5000e+01, 8.0000e+00, 3.8190e+03, 5.0000e+00, 3.2800e+02, 9.4200e+02,\n",
       "         3.3400e+02, 1.7710e+03, 1.3790e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 2.7000e+01, 2.2500e+02,\n",
       "         1.7150e+03, 1.3500e+02, 5.0000e+00, 2.7000e+01, 3.3370e+03, 1.4900e+02,\n",
       "         6.2300e+02, 7.9000e+01, 6.6100e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 3.2800e+02, 1.0860e+03,\n",
       "         6.6100e+02, 1.2000e+01, 8.0000e+00, 4.0330e+03, 6.0000e+00, 8.1000e+01,\n",
       "         3.0000e+00, 9.0000e+00, 7.7280e+03, 2.7000e+01, 3.1700e+02, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01,\n",
       "         4.6500e+02, 6.0000e+00, 2.4000e+01, 1.3300e+02, 3.6000e+01, 8.1000e+01,\n",
       "         2.2000e+02, 2.2860e+03, 5.0000e+00, 2.7000e+01, 1.0860e+03, 1.6300e+02,\n",
       "         6.6100e+02, 6.0000e+00, 3.9600e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 1.5480e+03, 6.0000e+00,\n",
       "         2.0870e+03, 1.1800e+03, 2.8000e+01, 1.1900e+02, 1.5100e+02, 5.6000e+01,\n",
       "         4.2800e+02, 2.5000e+01, 7.2000e+01, 8.2700e+02, 5.0000e+00, 3.6600e+02,\n",
       "         2.7000e+01, 3.7240e+03, 2.8000e+01, 7.1700e+02, 6.0000e+00, 2.7000e+01,\n",
       "         3.7300e+02, 2.8100e+02, 3.6270e+03, 1.1000e+01, 2.5300e+04, 5.0000e+00,\n",
       "         2.0698e+04, 1.0000e+01, 3.0000e+00, 1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.0180e+03, 6.0000e+00, 8.2000e+01, 2.5120e+03, 1.3100e+02,\n",
       "         7.1800e+02, 1.4000e+02, 1.1000e+01, 1.3800e+03, 1.4000e+02, 1.2000e+01,\n",
       "         1.4320e+03, 9.5000e+01, 3.0000e+00, 9.0000e+00, 3.2700e+03, 2.4000e+01,\n",
       "         2.5500e+02, 1.4100e+02, 2.1920e+03, 1.2631e+04, 5.0000e+00, 3.7000e+01,\n",
       "         5.6400e+02, 1.9000e+01, 6.2000e+03, 1.5900e+02, 1.0039e+04, 1.3626e+04,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03,\n",
       "         1.0000e+01, 5.3100e+02, 2.5000e+01, 4.3000e+01, 8.0000e+00, 3.8100e+02,\n",
       "         2.8000e+01, 2.5000e+01, 5.8000e+01, 1.0100e+02, 4.3000e+01, 7.6200e+02,\n",
       "         3.0000e+00, 9.7410e+03, 5.7000e+01, 3.8100e+02, 6.0000e+00, 5.9000e+01,\n",
       "         5.7000e+01, 5.6400e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         5.3600e+02, 4.6630e+03, 1.0000e+01, 4.9900e+02, 2.5120e+03, 7.3700e+02,\n",
       "         3.1000e+01, 1.7000e+01, 4.9700e+02, 9.5900e+02, 8.1000e+01, 2.3020e+03,\n",
       "         5.0000e+00, 3.5680e+03, 6.0000e+00, 1.3200e+02, 3.9800e+02, 3.6000e+01,\n",
       "         1.2800e+02, 1.9400e+02, 2.5000e+01, 5.4000e+01, 2.5300e+02, 3.4000e+01,\n",
       "         5.0000e+00, 4.5100e+02, 5.2300e+02, 2.4000e+01, 3.2700e+03, 2.1000e+01,\n",
       "         3.0000e+00, 9.0000e+00, 2.6340e+03, 2.5950e+03, 6.2000e+01, 3.3000e+01,\n",
       "         7.0780e+03, 8.9880e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 2.7000e+01, 5.4000e+01, 3.2000e+02,\n",
       "         3.4000e+01, 9.5000e+01, 3.0000e+00, 9.9000e+01, 2.5000e+01, 1.4230e+03,\n",
       "         1.2500e+02, 2.3900e+02, 2.5500e+02, 1.9400e+03, 3.4000e+01, 1.6000e+01,\n",
       "         5.0000e+00, 2.7000e+01, 5.4000e+01, 1.5880e+03, 1.6000e+02, 5.6400e+02,\n",
       "         9.5000e+01, 2.8000e+01, 8.0000e+00, 3.8100e+02, 1.6000e+01, 8.2000e+01,\n",
       "         4.5500e+02, 4.8400e+02, 5.0000e+00, 2.0698e+04, 1.0000e+01, 3.0000e+00,\n",
       "         1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.7000e+01, 2.1400e+02, 2.5000e+01, 3.1000e+01, 6.0000e+01,\n",
       "         2.0850e+03, 6.3000e+01, 1.1000e+01, 2.7000e+01, 5.5910e+03, 1.2000e+01,\n",
       "         1.3965e+04, 2.5000e+01, 6.0000e+00, 6.8000e+01, 2.7000e+01, 3.1700e+02,\n",
       "         2.5000e+01, 3.1000e+01, 6.0000e+01, 1.4800e+03, 2.1000e+01, 1.6100e+02,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03,\n",
       "         1.0000e+01, 3.3590e+03, 6.0000e+00, 1.5000e+02, 5.0000e+00, 2.7000e+01,\n",
       "         1.5687e+04, 1.2000e+01, 9.1900e+02, 8.0000e+00, 6.1960e+03, 6.7020e+03,\n",
       "         3.0000e+01, 5.5000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02,\n",
       "         4.6630e+03, 1.0000e+01, 1.0080e+03, 3.1000e+01, 1.7000e+01, 3.5160e+03,\n",
       "         5.0000e+00, 2.7000e+01, 5.4000e+01, 4.2800e+02, 2.5000e+01, 3.0000e+00,\n",
       "         9.0000e+00, 5.6560e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 1.5620e+03, 2.5000e+01, 5.0000e+00,\n",
       "         1.4800e+02, 1.0970e+03, 1.4000e+02, 5.0000e+00, 2.0698e+04, 1.0000e+01,\n",
       "         3.0000e+00, 1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.4200e+02, 8.0000e+00, 9.1000e+02, 1.8900e+02, 7.6850e+03,\n",
       "         1.3000e+01, 8.0000e+00, 2.1010e+03, 1.3000e+01, 8.0000e+00, 3.5950e+03,\n",
       "         6.2000e+01, 3.3000e+01, 3.5200e+02, 1.2000e+01, 4.3000e+01, 3.0000e+00,\n",
       "         9.0000e+00, 1.0880e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 4.6600e+02, 3.1000e+01, 7.0000e+00,\n",
       "         3.0000e+00, 9.0000e+00, 1.6270e+03, 1.9400e+02, 1.2000e+01, 4.0360e+03,\n",
       "         4.8000e+01, 1.9070e+03, 6.2500e+02, 3.5950e+03, 5.5000e+01, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 2.7000e+01,\n",
       "         3.0000e+00, 2.0964e+04, 2.5000e+01, 1.3300e+02, 3.6000e+01, 4.4030e+03,\n",
       "         1.2000e+01, 2.6463e+04, 2.8000e+01, 1.4000e+02, 2.1000e+01, 1.0880e+03,\n",
       "         9.1200e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 4.6600e+02, 1.9000e+01, 2.6900e+02, 9.5000e+01,\n",
       "         8.2000e+01, 1.8540e+03, 6.3000e+01, 5.0000e+00, 1.4800e+02, 4.9700e+02,\n",
       "         1.0880e+03, 1.1000e+01, 2.7000e+01, 3.1000e+01, 5.1000e+01, 1.3200e+02,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 7.7100e+03, 5.0000e+00, 9.4000e+01, 5.6000e+01, 3.6000e+01,\n",
       "         5.3900e+02, 1.2000e+01, 8.0000e+00, 4.5200e+02, 1.1000e+01, 6.2000e+01,\n",
       "         1.6900e+04, 1.0209e+04, 8.1000e+01, 8.7400e+02, 1.2000e+01, 2.3910e+03,\n",
       "         6.1890e+03, 1.5100e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         3.5700e+02, 4.6630e+03, 1.0000e+01, 2.0030e+03, 3.4000e+01, 3.6000e+01,\n",
       "         4.6000e+01, 6.6000e+01, 2.3900e+02, 6.0500e+02, 5.8000e+01, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 2.1630e+03,\n",
       "         5.0000e+00, 2.7500e+02, 6.2000e+01, 7.1220e+03, 2.8000e+01, 8.0000e+00,\n",
       "         6.9000e+02, 1.1000e+01, 6.2000e+01, 4.3000e+01, 6.0590e+03, 1.2000e+01,\n",
       "         1.6900e+02, 8.0000e+00, 2.4470e+03, 1.2487e+04, 1.2000e+01, 8.0000e+00,\n",
       "         3.5950e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 4.6600e+02, 4.7000e+01, 1.7040e+03, 1.6310e+03,\n",
       "         5.0000e+00, 2.0698e+04, 1.0000e+01, 3.0000e+00, 1.0000e+00],\n",
       "        device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 2.6450e+03, 4.7400e+02, 4.8000e+01, 9.8720e+03, 1.3000e+01,\n",
       "         1.3254e+04, 1.6000e+01, 8.2000e+01, 8.2800e+02, 5.8000e+01, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 1.3390e+04,\n",
       "         5.0000e+00, 4.5100e+02, 2.4300e+02, 2.5000e+01, 1.3000e+02, 3.5200e+02,\n",
       "         1.2000e+01, 2.4000e+02, 1.3500e+02, 2.2300e+02, 1.2000e+01, 8.0000e+00,\n",
       "         3.5950e+03, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02,\n",
       "         4.6630e+03, 1.0000e+01, 3.3590e+03, 6.0000e+00, 2.4000e+01, 3.1000e+01,\n",
       "         7.0000e+00, 2.6900e+02, 5.0000e+00, 4.5100e+02, 4.1000e+02, 9.8700e+02,\n",
       "         1.4000e+02, 1.2000e+01, 2.4000e+02, 1.2800e+02, 1.3254e+04, 2.2300e+02,\n",
       "         2.1000e+01, 1.6000e+02, 5.0000e+00, 2.7000e+01, 1.5510e+03, 1.5687e+04,\n",
       "         5.0000e+00, 2.0698e+04, 1.0000e+01, 3.0000e+00, 1.0000e+00],\n",
       "        device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 3.6300e+02, 5.4000e+01, 2.7000e+01, 1.0300e+02, 5.8000e+01,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         3.7000e+01, 3.5800e+02, 2.4679e+04, 1.1600e+02, 2.7000e+01, 4.7000e+01,\n",
       "         2.1061e+04, 3.0000e+01, 8.0000e+00, 1.3960e+03, 5.0000e+00, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 3.9630e+03,\n",
       "         2.5000e+01, 2.8100e+02, 1.2000e+01, 1.3600e+02, 6.0160e+03, 4.7500e+02,\n",
       "         5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03,\n",
       "         1.0000e+01, 4.6500e+02, 6.0000e+00, 2.9900e+02, 4.0500e+02, 2.4000e+01,\n",
       "         1.0520e+03, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02,\n",
       "         4.6630e+03, 1.0000e+01, 2.1630e+03, 6.0000e+00, 3.9000e+01, 1.2180e+03,\n",
       "         5.4000e+01, 3.6000e+01, 1.1530e+03, 1.6000e+01, 8.9000e+01, 7.6330e+03,\n",
       "         5.7000e+01, 6.7220e+03, 3.0000e+00, 9.9000e+01, 2.5000e+01, 1.0300e+02,\n",
       "         2.4000e+01, 5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02,\n",
       "         4.6630e+03, 1.0000e+01, 2.7000e+01, 2.1700e+02, 5.0000e+00, 2.7000e+01,\n",
       "         3.1000e+01, 2.6000e+01, 3.9400e+02, 4.7000e+02, 6.5300e+02, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01,\n",
       "         4.6600e+02, 3.1000e+01, 7.0000e+00, 7.6240e+03, 5.0000e+00, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 5.3100e+02,\n",
       "         2.5000e+01, 2.1400e+02, 1.2500e+02, 3.1000e+01, 7.0000e+00, 1.7860e+03,\n",
       "         2.8000e+01, 8.2000e+01, 2.1040e+03, 5.8000e+01, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 5.5500e+02, 1.9620e+03,\n",
       "         5.0000e+00, 3.3590e+03, 6.0000e+00, 4.2730e+03, 6.0000e+00, 3.4000e+01,\n",
       "         4.7000e+01, 1.6000e+01, 8.9000e+01, 7.6330e+03, 5.7000e+01, 3.0000e+00,\n",
       "         9.0000e+00, 6.7220e+03, 6.0000e+00, 1.1000e+01, 2.5000e+01, 1.4100e+02,\n",
       "         1.5000e+02, 2.8216e+04, 8.8900e+02, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 2.7000e+01, 7.0000e+00,\n",
       "         1.1810e+03, 1.8000e+01, 1.8095e+04, 8.8900e+02, 1.3160e+03, 2.1000e+01,\n",
       "         3.0000e+00, 9.0000e+00, 2.1040e+03, 5.8000e+01, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01, 1.1290e+03, 5.0300e+02,\n",
       "         5.0000e+00, 1.4800e+02, 3.1000e+01, 2.6000e+01, 3.9400e+02, 6.6900e+02,\n",
       "         4.2400e+02, 8.1000e+01, 3.4000e+01, 5.0000e+00, 1.7130e+03, 3.4500e+02,\n",
       "         1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 2.7000e+01, 3.1000e+01,\n",
       "         5.1000e+01, 7.4030e+03, 4.2730e+03, 5.0000e+00, 2.9900e+02, 1.2500e+02,\n",
       "         8.1000e+01, 8.0000e+00, 3.3100e+02, 2.7000e+01, 5.8160e+03, 1.6000e+01,\n",
       "         8.0000e+00, 1.2180e+03, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         5.3600e+02, 4.6630e+03, 1.0000e+01, 1.0080e+03, 3.1000e+01, 1.7000e+01,\n",
       "         3.5160e+03, 6.0000e+00, 3.4000e+01, 2.2500e+02, 4.3000e+01, 1.1800e+02,\n",
       "         5.0460e+03, 3.2690e+03, 5.0000e+00, 2.7500e+02, 2.7000e+01, 2.4000e+02,\n",
       "         4.6000e+01, 1.1810e+03, 1.8000e+01, 1.8095e+04, 8.8900e+02, 2.8000e+01,\n",
       "         1.4000e+02, 5.0000e+00, 5.3100e+02, 2.5000e+01, 2.4100e+02, 1.4000e+02,\n",
       "         1.2000e+01, 2.4380e+03, 3.4000e+01, 2.3000e+02, 5.8000e+01, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 2.1630e+03,\n",
       "         6.0000e+00, 7.5400e+02, 5.0000e+00, 2.7000e+01, 3.1000e+01, 1.9500e+02,\n",
       "         3.1000e+02, 3.6530e+03, 2.4000e+01, 5.0000e+00, 2.0698e+04, 1.0000e+01,\n",
       "         3.0000e+00, 1.0000e+00], device='mps:0'),\n",
       " tensor([1.2198e+04, 1.6350e+03, 1.7370e+03, 8.0000e+00, 8.2600e+02, 3.6340e+03,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 1.0720e+03, 2.7000e+01, 1.9900e+02, 2.5000e+01, 5.8000e+01,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         2.1630e+03, 6.0000e+00, 2.7000e+01, 3.1000e+01, 5.1000e+01, 6.9200e+02,\n",
       "         1.2800e+02, 5.8500e+02, 3.0000e+01, 3.3850e+03, 2.0927e+04, 5.0000e+00,\n",
       "         5.3100e+02, 2.5000e+01, 4.3000e+01, 1.3600e+02, 1.3350e+03, 3.0000e+01,\n",
       "         8.0000e+00, 1.4260e+03, 5.8000e+01, 1.7130e+03, 3.4500e+02, 1.3515e+04,\n",
       "         5.3600e+02, 4.6630e+03, 1.0000e+01, 5.0600e+02, 1.3350e+03, 1.4700e+02,\n",
       "         2.7000e+02, 3.3000e+01, 8.1000e+01, 4.9130e+03, 8.9200e+02, 5.0000e+00,\n",
       "         3.2800e+02, 4.2900e+02, 3.6000e+01, 2.6900e+03, 5.0000e+00, 1.7130e+03,\n",
       "         3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01, 1.0720e+03,\n",
       "         2.7000e+01, 6.9100e+02, 4.8000e+01, 8.0000e+01, 9.1000e+01, 5.8000e+01,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03, 1.0000e+01,\n",
       "         2.7000e+01, 3.1000e+01, 5.1000e+01, 8.0320e+03, 5.0000e+00, 9.4000e+01,\n",
       "         3.1000e+01, 7.0000e+00, 2.1000e+01, 2.8480e+03, 1.6300e+02, 6.0000e+00,\n",
       "         7.8000e+01, 3.4000e+01, 3.9800e+02, 1.0490e+03, 1.6000e+01, 8.0000e+00,\n",
       "         3.5950e+03, 5.0000e+00, 2.9900e+02, 2.5000e+01, 3.1000e+01, 6.0000e+01,\n",
       "         2.2220e+03, 1.2000e+01, 3.2000e+02, 1.9000e+02, 3.4000e+01, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         8.8720e+03, 5.0000e+00, 2.7500e+02, 2.7000e+01, 3.1000e+01, 2.6000e+01,\n",
       "         1.1400e+02, 1.2000e+01, 6.9100e+02, 1.7500e+02, 1.3350e+03, 9.1000e+01,\n",
       "         5.0000e+00, 1.7130e+03, 3.4500e+02, 1.3515e+04, 5.3600e+02, 4.6630e+03,\n",
       "         1.0000e+01, 4.3200e+02, 2.6900e+02, 5.0000e+00, 3.2800e+02, 3.1000e+01,\n",
       "         6.0000e+01, 7.8800e+02, 2.2300e+02, 4.1600e+02, 2.8750e+03, 5.0000e+00,\n",
       "         1.7130e+03, 3.4500e+02, 1.3515e+04, 3.5700e+02, 4.6630e+03, 1.0000e+01,\n",
       "         1.3330e+03, 2.1000e+01, 3.9000e+01, 1.9900e+02, 5.0000e+00, 2.0698e+04,\n",
       "         1.0000e+01, 3.0000e+00, 1.0000e+00], device='mps:0')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tensors = batch[\"input_ids\"]\n",
    "prompt_tensors = [tensor.float() for tensor in prompt_tensors]\n",
    "prompt_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl.core import LengthSampler\n",
    "\n",
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 10\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # Break when you reach max_steps\n",
    "    if step >= max_ppo_steps:\n",
    "        break\n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # Get response from FLAN-T5/PEFT LLM\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()\n",
    "\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        # Throws type error since M1 doesn't support BFloat16: https://github.com/pytorch/pytorch/issues/78168#issuecomment-1513598356\n",
    "        summary = ppo_trainer.generate(prompt_tensor.long(), **generation_kwargs)\n",
    "\n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "\n",
    "    # This needs to be called \"response\"\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # Compute reward outputs\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]    \n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "    # We use the `nothate` item because this is the score for the positive `nothate` class.\n",
    "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]\n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "\n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Evaluate the Model Quantitatively\n",
    "\n",
    "Load the PPO/PEFT model back in from disk and use the test dataset split to evaluate the toxicity score of the RL-fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throws type error since M1 doesn't support BFloat16: https://github.com/pytorch/pytorch/issues/78168#issuecomment-1513598356\n",
    "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model, \n",
    "                                                                        toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                        tokenizer=tokenizer, \n",
    "                                                                        dataset=dataset[\"test\"], \n",
    "                                                                        num_samples=10)\n",
    "\n",
    "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare the toxicity scores of the reference model (before detoxification) and fine-tuned model (after detoxification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
    "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
    "\n",
    "print(f'Percentage improvement of toxicity score after detoxification:')\n",
    "print(f'mean: {mean_improvement*100:.2f}%')\n",
    "print(f'std: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Evaluate the Model Qualitatively\n",
    "\n",
    "Let's inspect some examples from the test dataset. You can compare the original `ref_model` to the fine-tuned/detoxified `ppo_model` using the toxicity evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "compare_results = {}\n",
    "\n",
    "df_batch = dataset[\"test\"][0:batch_size]\n",
    "\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# Get response from ppo and base model.\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "    \n",
    "    summary = ref_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# Decode responses.\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after.\n",
    "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store and review the results in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the reward mean/median of the generated sequences you can observe a significant difference!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
